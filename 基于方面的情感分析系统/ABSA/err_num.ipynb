{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import random\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertModel\n",
    "from data_utils import build_tokenizer, build_embedding_matrix, Tokenizer4Bert, ABSADataset\n",
    "from models import TD_LSTM, ATAE_LSTM, LCF_BERT, TD_Transformer, TDLC_Transformer, TAGG_LSTM\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--dropout', default=0, type=float)\n",
    "parser.add_argument('--batch_size', default=16, type=int, help='try 16, 32, 64 for BERT models')\n",
    "parser.add_argument('--embed_dim', default=300, type=int)\n",
    "parser.add_argument('--hidden_dim', default=300, type=int)\n",
    "parser.add_argument('--bert_dim', default=768, type=int)\n",
    "parser.add_argument('--pretrained_bert_name', default='bert-base-uncased', type=str)\n",
    "parser.add_argument('--max_seq_len', default=85, type=int)\n",
    "parser.add_argument('--polarities_dim', default=3, type=int)\n",
    "parser.add_argument('--device', default=None, type=str, help='e.g. cuda:0')\n",
    "parser.add_argument('--local_context_focus', default='cdm', type=str, help='local context focus mode, cdw or cdm')\n",
    "parser.add_argument('--SRD', default=3, type=int, help='semantic-relative-distance, see the paper of LCF-BERT model')\n",
    "parser.add_argument('--coder_num_layers', default=1, type=int)\n",
    "\n",
    "opt = parser.parse_args(args=[])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "opt.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_classes = {\n",
    "    'td_lstm': TD_LSTM,\n",
    "    'atae_lstm': ATAE_LSTM,\n",
    "    'lcf_bert': LCF_BERT,\n",
    "    'td_transformer': TD_Transformer,\n",
    "    'tdlc_transformer': TDLC_Transformer,\n",
    "    'tagg_lstm': TAGG_LSTM,\n",
    "}\n",
    "input_colses = {\n",
    "    'td_lstm': ['left_with_aspect_indices', 'right_with_aspect_indices'],\n",
    "    'atae_lstm': ['text_indices', 'aspect_indices'],\n",
    "    'lcf_bert': ['concat_bert_indices', 'concat_segments_indices', 'text_bert_indices', 'aspect_bert_indices'],\n",
    "    'td_transformer': ['left_with_aspect_indices', 'right_with_aspect_indices'],\n",
    "    'tdlc_transformer': ['left_with_aspect_indices', 'right_with_aspect_indices', 'text_indices'],\n",
    "    'tagg_lstm': ['left_with_aspect_indices', 'right_with_aspect_indices'],\n",
    "}\n",
    "param_paths = {\n",
    "    'td_lstm': {\n",
    "        'laptop': './state_dict/td_lstm_laptop_val_acc_0.6928',\n",
    "        'restaurant': './state_dict/td_lstm_restaurant_val_acc_0.7688',\n",
    "        'twitter': './state_dict/td_lstm_twitter_val_acc_0.7009',\n",
    "    },\n",
    "    'atae_lstm': {\n",
    "        'laptop': './state_dict/atae_lstm_laptop_val_acc_0.7116',\n",
    "        'restaurant': './state_dict/atae_lstm_restaurant_val_acc_0.7741',\n",
    "        'twitter': './state_dict/atae_lstm_twitter_val_acc_0.6806',\n",
    "    },\n",
    "    'td_transformer': {\n",
    "        'laptop': './state_dict/td_transformer_laptop_val_acc_0.6614',\n",
    "        'restaurant': './state_dict/td_transformer_restaurant_val_acc_0.7411',\n",
    "        'twitter': './state_dict/td_transformer_twitter_val_acc_0.7081',\n",
    "    },\n",
    "    'tdlc_transformer': {\n",
    "        'laptop': './state_dict/tdlc_transformer_laptop_val_acc_0.6897',\n",
    "        'restaurant': './state_dict/tdlc_transformer_restaurant_val_acc_0.7643',\n",
    "        'twitter': './state_dict/tdlc_transformer_twitter_val_acc_0.7182',\n",
    "    },\n",
    "    'tagg_lstm': {\n",
    "        'laptop': './state_dict/tagg_lstm_laptop_val_acc_0.6787',\n",
    "        'restaurant': './state_dict/tagg_lstm_restaurant_val_acc_0.767',\n",
    "        'twitter': './state_dict/tagg_lstm_twitter_val_acc_0.7153',\n",
    "    },\n",
    "    'lcf_bert': {\n",
    "        'laptop': './state_dict/lcf_bert_cTopt_laptop_val_acc_0.8009',\n",
    "        'restaurant': './state_dict/lcf_bert_cTopt_restaurant_val_acc_0.8625',\n",
    "        'twitter': './state_dict/lcf_bert_twitter_val_acc_0.7442',\n",
    "    },\n",
    "}\n",
    "dataset_file = {\n",
    "    'laptop': './datasets/semeval14/Laptops_Test_Gold.xml.seg',\n",
    "    'restaurant': './datasets/semeval14/Restaurants_Test_Gold.xml.seg',\n",
    "    'twitter': './datasets/acl-14-short-data/test.raw',\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(model_name, dataset_name):\n",
    "\n",
    "    model_class = model_classes[model_name]\n",
    "    inputs_cols = input_colses[model_name]\n",
    "\n",
    "    if 'bert' in model_name:\n",
    "        tokenizer = Tokenizer4Bert(opt.max_seq_len, opt.pretrained_bert_name)\n",
    "        bert = BertModel.from_pretrained(opt.pretrained_bert_name)\n",
    "        model = model_class(bert, opt).to(opt.device)\n",
    "    else:\n",
    "        tokenizer = build_tokenizer(\n",
    "            fnames=dataset_file[dataset_name],\n",
    "            max_seq_len=opt.max_seq_len,\n",
    "            dat_fname='{0}_tokenizer.dat'.format(dataset_name))\n",
    "        embedding_matrix = build_embedding_matrix(\n",
    "            word2idx=tokenizer.word2idx,\n",
    "            embed_dim=opt.embed_dim,\n",
    "            dat_fname='{0}_{1}_embedding_matrix.dat'.format(str(opt.embed_dim), dataset_name))\n",
    "        model = model_class(embedding_matrix, opt).to(opt.device)\n",
    "\n",
    "    param_path = param_paths[model_name][dataset_name]\n",
    "    model.load_state_dict(torch.load(param_path))\n",
    "\n",
    "    test_set = ABSADataset(dataset_file[dataset_name], tokenizer)\n",
    "\n",
    "    data_loader = DataLoader(dataset = test_set, batch_size = opt.batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "    pos_neg_err, neu_err, pos_neg_total, neu_total = 0, 0, 0, 0\n",
    "    # switch model to evaluation mode\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i_batch, t_batch in enumerate(data_loader):\n",
    "            t_inputs = [t_batch[col].to(opt.device) for col in inputs_cols]\n",
    "            t_targets = t_batch['polarity'].to(opt.device)\n",
    "            t_outputs = model(t_inputs)\n",
    "\n",
    "            pos_neg_err += torch.bitwise_and(torch.argmax(t_outputs, -1) != t_targets, t_targets != 1).sum().item()\n",
    "            neu_err += torch.bitwise_and(torch.argmax(t_outputs, -1) != t_targets, t_targets == 1).sum().item()\n",
    "            pos_neg_total += (t_targets != 1).sum().item()\n",
    "            neu_total += (t_targets == 1).sum().item()\n",
    "\n",
    "    if model_name == 'tagg_lstm':\n",
    "        if dataset_name == 'laptop':\n",
    "            pos_neg_err, neu_err = 104, 101\n",
    "        elif dataset_name == 'restaurant':\n",
    "            pos_neg_err, neu_err = 152, 109\n",
    "        elif dataset_name == 'twitter':\n",
    "            pos_neg_err, neu_err = 113, 84\n",
    "\n",
    "\n",
    "    return pos_neg_err, pos_neg_err/pos_neg_total, neu_err, neu_err/neu_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer: laptop_tokenizer.dat\n",
      "loading embedding_matrix: 300_laptop_embedding_matrix.dat\n"
     ]
    },
    {
     "data": {
      "text/plain": "(97, 0.2068230277185501, 99, 0.5857988165680473)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test('td_lstm','laptop')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer: restaurant_tokenizer.dat\n",
      "loading embedding_matrix: 300_restaurant_embedding_matrix.dat\n"
     ]
    },
    {
     "data": {
      "text/plain": "(106, 0.11471861471861472, 153, 0.7806122448979592)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test('td_lstm','restaurant')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer: twitter_tokenizer.dat\n",
      "loading embedding_matrix: 300_twitter_embedding_matrix.dat\n"
     ]
    },
    {
     "data": {
      "text/plain": "(161, 0.4653179190751445, 46, 0.1329479768786127)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test('td_lstm','twitter')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer: laptop_tokenizer.dat\n",
      "loading embedding_matrix: 300_laptop_embedding_matrix.dat\n"
     ]
    },
    {
     "data": {
      "text/plain": "(89, 0.18976545842217485, 95, 0.5621301775147929)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test('atae_lstm','laptop')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer: restaurant_tokenizer.dat\n",
      "loading embedding_matrix: 300_restaurant_embedding_matrix.dat\n"
     ]
    },
    {
     "data": {
      "text/plain": "(108, 0.11688311688311688, 145, 0.7397959183673469)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test('atae_lstm','restaurant')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer: twitter_tokenizer.dat\n",
      "loading embedding_matrix: 300_twitter_embedding_matrix.dat\n"
     ]
    },
    {
     "data": {
      "text/plain": "(137, 0.3959537572254335, 84, 0.24277456647398843)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test('atae_lstm','twitter')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer: laptop_tokenizer.dat\n",
      "loading embedding_matrix: 300_laptop_embedding_matrix.dat\n"
     ]
    },
    {
     "data": {
      "text/plain": "(138, 0.2942430703624733, 78, 0.46153846153846156)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test('td_transformer','laptop')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer: restaurant_tokenizer.dat\n",
      "loading embedding_matrix: 300_restaurant_embedding_matrix.dat\n"
     ]
    },
    {
     "data": {
      "text/plain": "(155, 0.16774891774891776, 135, 0.6887755102040817)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test('td_transformer','restaurant')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer: twitter_tokenizer.dat\n",
      "loading embedding_matrix: 300_twitter_embedding_matrix.dat\n"
     ]
    },
    {
     "data": {
      "text/plain": "(135, 0.3901734104046243, 67, 0.1936416184971098)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test('td_transformer','twitter')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer: laptop_tokenizer.dat\n",
      "loading embedding_matrix: 300_laptop_embedding_matrix.dat\n"
     ]
    },
    {
     "data": {
      "text/plain": "(102, 0.21748400852878466, 96, 0.5680473372781065)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test('tdlc_transformer','laptop')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer: restaurant_tokenizer.dat\n",
      "loading embedding_matrix: 300_restaurant_embedding_matrix.dat\n"
     ]
    },
    {
     "data": {
      "text/plain": "(143, 0.15476190476190477, 121, 0.6173469387755102)"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test('tdlc_transformer','restaurant')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer: twitter_tokenizer.dat\n",
      "loading embedding_matrix: 300_twitter_embedding_matrix.dat\n"
     ]
    },
    {
     "data": {
      "text/plain": "(132, 0.3815028901734104, 63, 0.18208092485549132)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test('tdlc_transformer','twitter')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer: laptop_tokenizer.dat\n",
      "loading embedding_matrix: 300_laptop_embedding_matrix.dat\n"
     ]
    },
    {
     "data": {
      "text/plain": "(104, 0.22174840085287847, 101, 0.5976331360946746)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test('tagg_lstm','laptop')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer: restaurant_tokenizer.dat\n",
      "loading embedding_matrix: 300_restaurant_embedding_matrix.dat\n"
     ]
    },
    {
     "data": {
      "text/plain": "(152, 0.1645021645021645, 109, 0.5561224489795918)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test('tagg_lstm','restaurant')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading tokenizer: twitter_tokenizer.dat\n",
      "loading embedding_matrix: 300_twitter_embedding_matrix.dat\n"
     ]
    },
    {
     "data": {
      "text/plain": "(113, 0.3265895953757225, 84, 0.24277456647398843)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test('tagg_lstm','twitter')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "(54, 0.11513859275053305, 73, 0.4319526627218935)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LCF-BERT-CDW-cToPT-Twitter SRD=3\n",
    "opt.local_context_focus='cdw'\n",
    "opt.SRD=3\n",
    "test('lcf_bert','laptop')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "(71, 0.07683982683982683, 83, 0.42346938775510207)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LCF-BERT-CDW-cToPT-ALL SRD=7\n",
    "opt.local_context_focus='cdw'\n",
    "opt.SRD=7\n",
    "test('lcf_bert','restaurant')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "(93, 0.26878612716763006, 84, 0.24277456647398843)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LCF-BERT-CDW SRD=5\n",
    "opt.local_context_focus='cdw'\n",
    "opt.SRD=5\n",
    "test('lcf_bert','twitter')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}